使用Apache Lucene创建索引，进行搜索

Lucene总体架构
1，文档document：索引与搜索的主要载体，包含一个或多个字段，存放将要写入索引或者将从索引搜索出来的数据
2，字段field：文档的一个片段，包括字段的名称与内容
3，词项term：搜索时的一个单位，代表文本中的某个词
4，词条token：词项在字段中的一次出现，包括词项的文本，开始和结束的位移以及类型

inverted index倒排索引，将词项映射到文档中的数据结构，倒排索引面向词项
索引后每个词项指向该词条出现过的文档，还有一个与之关联的计数（即文档频率）

词向量，为单个字段创建的小索引，存储该字段中所有的词条

segment段，每个索引由多个段组成，每个段只会被创建一次但会被查询多次。索引期间，段经过创建就不会被修改。
例如，文档被删除以后，删除信息会被单独保存在一个文件中，而段本身并没有修改

segments merge段合并，多个段会在段合并阶段被合并在一起，而且要么强制执行，要么有Lucene的内在
机制决定在某个时刻执行，合并后段的数量更少，但是更大。段合并非常耗I/O，且合并期间有些不再使用的
信息也会被清理调。 注意：请不要强制进行合并，仔细配置段合并的策略即可

analysis分析，文本分析由分析器来执行，而分析器由分词器tokenizer，过滤器filter和字符映射
组成character mapper.s

Lucene的分词器用来将文本切割成词条，其中携带各种额外信息的词项，这些信息包括
：词项目在原始文本中的位置，词项的长度。分词器的工作成果成为词条流，因为这些
词条被一个一个的退送给过滤器处理。

过滤器是可选的，可以为0个，1个或者多个，用于处理词条流中的词条。例如，它可以
移除，修改词条流中的词条，甚至可以创造新的词条。
Lucene提供了很多现成的过滤器
当分析器中有多个过滤器时，会逐个处理

字符映射器，用于调用分词器之前的文本与处理操作，如HTML文本的去标签处理。

索引与查询
Lucene使用你选择的分析器来处理文档中的内容，并可以对不同的字段使用不同的分词器
。在检索时，如果使用了某个查询分析器query parser，那么查询串就会被分析，而有些
则不会。ElasticSearch中有些查询会被分析，而有些则不会。例如，前缀查询prefix query不会被分析，而匹配查询match query会被
分析。

注意，索引期与检索期的文本分析要采用相同的分析器，只有查询分析出来的词项与索引中词项
能匹配上，才会返回预期的文档集。例如，索引期使用了词干还原与小写转换，那么在查询期
也应该使对查询串做相同的处理，否则查询可能不会返回任何结果。

Lucene查询语言
在Lucene中，一个查询通常被分割为词项与操作符。Lucene中的词项可以是个单个词，
也可以是一个短语（用双引号括起来的一组词）。如果设置了查询分析过程，那么预先选定的分析器将会对查询
中的所有词汇进行处理。
AND OR NOT
+，只有包含+操作符后面的词项的文档才会被认为是与从句匹配 +lucene apache表示必须包含lucene，apache可出现可不出现
-，与从句匹配的文档不能出现-操作符后的词项 +lucene-elasticsearch表示查找包含lucene但不包含elasticsearch的文档

如果查询中没有出现前面提到的任何操作符，那么默认使用OR

词项修饰符
Lucene支持两种通配符?,*
?匹配的单个
*匹配多个三
